---
- name: Label storage nodes
  hosts: ceph_storage_nodes
  tags: label_nodes
  tasks:
    - name: Label storage nodes
      kubernetes.core.k8s:
        definition:
          apiVersion: v1
          kind: Node
          metadata:
            name: "{{ inventory_hostname }}"
            labels:
              role: storage-node
      delegate_to: localhost

- name: Label control plane nodes
  hosts: openstack_control_plane
  tags: label_nodes
  tasks:
    - name: Label control plane nodes
      kubernetes.core.k8s:
        definition:
          apiVersion: v1
          kind: Node
          metadata:
            name: "{{ inventory_hostname }}"
            labels:
              openstack-control-plane: enabled
      delegate_to: localhost

# Commenting this out since the doc limits to the first three controller nodes
# and this will enable vault storage on all of the controller nodes
# - name: Label vault nodes
#   hosts: openstack_control_plane
#   tasks:
#     - name: Label vault nodes
#       kubernetes.core.k8s:
#         definition:
#           apiVersion: v1
#           kind: Node
#           metadata:
#             name: "{{ inventory_hostname }}"
#             labels:
#               vault-storage: enabled
#       delegate_to: localhost

- name: Label nova compute nodes
  hosts: nova_compute_nodes
  tags: label_nodes
  tasks:
    - name: Label nova compute nodes
      kubernetes.core.k8s:
        definition:
          apiVersion: v1
          kind: Node
          metadata:
            name: "{{ inventory_hostname }}"
            labels:
              openstack-compute-node: enabled
      delegate_to: localhost

- name: Label openstack network nodes
  hosts: ovn_network_nodes:nova_compute_nodes
  tags: label_nodes
  tasks:
    - name: Label nova compute nodes
      kubernetes.core.k8s:
        definition:
          apiVersion: v1
          kind: Node
          metadata:
            name: "{{ inventory_hostname }}"
            labels:
              openstack-network-node: enabled
      delegate_to: localhost

- name: Label worker nodes
  hosts: openstack_control_plane:openstack_worker_nodes
  tags: label_nodes
  tasks:
    - name: Label worker nodes
      kubernetes.core.k8s:
        definition:
          apiVersion: v1
          kind: Node
          metadata:
            name: "{{ inventory_hostname }}"
            labels:
              node-role.kubernetes.io/worker: worker
      delegate_to: localhost

- name: Remove taint from controllers
  hosts: kube_control_plane
  tags: taint_nodes
  tasks:
    - name: Remove taint
      kubernetes.core.k8s_taint:
        state: absent
        name: "{{ inventory_hostname }}"
        taints:
          - effect: NoSchedule
      delegate_to: localhost

- name: Deploy k8s dashboard
  hosts: localhost
  connection: local
  tags: deploy_dashboard
  tasks:
    - name: Deploy k8s dashboard
      kubernetes.core.k8s:
        definition: "{{ lookup('kubernetes.core.kustomize', dir='/opt/genestack/kustomize.example/k8s-dashboard') }}"
        apply: true

- name: Deploy prometheus
  hosts: localhost
  connection: local
  tags: deploy_prometheus
  tasks:
    # Not happy about this but deploying prometheus fails on the first run.
    # TODO: Find a way to do this cleanly using the kubernetes.core.k8s module
    - name: Deploy prometheus # noqa: no-changed-when risky-shell-pipe
      ansible.builtin.shell:
        cmd: kubectl kustomize --enable-helm /opt/genestack/kustomize.example/prometheus | kubectl apply --server-side -f -
      retries: 2
      delay: 2
      register: deploy_prometheus_result
      until: deploy_prometheus_result is not failed

- name: Make helm charts
  hosts: localhost
  connection: local
  tags: make_helm_charts
  tasks:
    - name: Make helm charts
      community.general.make:
        chdir: "{{ item }}"
        target: all
      loop:
        - /opt/genestack/submodules/openstack-helm
        - /opt/genestack/submodules/openstack-helm-infra

## Ceph internal section
## https://docs.rackspacecloud.com/storage-ceph-rook-internal/
- name: Ceph internal
  hosts: localhost
  connection: local
  tags: ceph_internal
  tasks:
    - name: Hack to set image for the operator
      ansible.builtin.lineinfile:
        dest: "/opt/genestack/kustomize.example/rook-operator/operator.yaml"
        search_string: 'image: rook/ceph:master'
        line: "          image: rook/ceph:v1.13.7"
        state: present

    # https://docs.rackspacecloud.com/storage-ceph-rook-internal/#deploy-the-rook-operator
    # kubectl apply -k /opt/genestack/kustomize.example/rook-operator/
    - name: Deploy rook operator
      kubernetes.core.k8s:
        definition: "{{ lookup('kubernetes.core.kustomize', binary_path='/usr/local/bin/kubectl', dir='/opt/genestack/kustomize.example/rook-operator') }}"
        apply: true
        state: present
      register: result

    - name: Wait for rook operator deployment conditions
      kubernetes.core.k8s_info:
        name: rook-ceph-operator
        kind: Deployment
        namespace: rook-ceph
        wait: true
        wait_condition:
          type: "{{ item.type }}"
          reason: "{{ item.reason }}"
          status: "True"
      loop:
        - { type: 'Available', reason: 'MinimumReplicasAvailable'}
        - { type: 'Progressing', reason: 'NewReplicaSetAvailable'}

    - name: Wait for rook operator pod conditions
      kubernetes.core.k8s_info:
        api_version: v1
        # name: rook-ceph-operator
        kind: Pod
        label_selectors:
          - app = rook-ceph-operator
        namespace: rook-ceph
        wait: true
        wait_condition:
          type: "{{ item }}"
          status: "True"
      loop:
        - "Ready"
        - "ContainersReady"

    # https://docs.rackspacecloud.com/storage-ceph-rook-internal/#deploy-the-rook-cluster
    # kubectl apply -k /opt/genestack/kustomize.example/rook-cluster
    - name: Deploy rook cluster
      kubernetes.core.k8s:
        definition: "{{ lookup('kubernetes.core.kustomize', binary_path='/usr/local/bin/kubectl', dir='/opt/genestack/kustomize.example/rook-cluster') }}" # yamllint disable-line rule:line-length
        apply: true
        state: present

    - name: Wait for rook cluster deployment conditions
      kubernetes.core.k8s_info:
        api_version: "ceph.rook.io/v1"
        name: rook-ceph
        kind: CephCluster
        namespace: rook-ceph
        wait: true
        wait_condition:
          type: "{{ item.type }}"
          reason: "{{ item.reason }}"
          status: "True"
        wait_timeout: 900
      loop:
        - { type: 'Ready', reason: 'ClusterCreated'}

    # https://docs.rackspacecloud.com/storage-ceph-rook-internal/#create-storage-classes
    # kubectl apply -k /opt/genestack/kustomize.example/rook-defaults
    - name: Create storage classes
      kubernetes.core.k8s:
        definition: "{{ lookup('kubernetes.core.kustomize', binary_path='/usr/local/bin/kubectl', dir='/opt/genestack/kustomize.example/rook-defaults') }}" # yamllint disable-line rule:line-length
        apply: true
        state: present

### Infrastructre section
### https://docs.rackspacecloud.com/infrastructure-overview/

- name: OpenStack namespace
  hosts: localhost
  connection: local
  tags: openstack_namespace
  tasks:
    - name: Create OpenStack namespace
      kubernetes.core.k8s:
        name: openstack
        api_version: v1
        kind: Namespace
        state: present


### https://docs.rackspacecloud.com/infrastructure-mariadb/
- name: MariaDB
  hosts: localhost
  connection: local
  tags: mariadb
  vars:
    secret_name: mariadb
    cluster_name: cluster.local
  tasks:
    - name: Get secret if exists
      kubernetes.core.k8s_info:
        api_version: v1
        kind: Secret
        name: "{{ secret_name }}"
        namespace: openstack
      register: maraiadb_secret_output

    - name: Create secret if it does not exist
      kubernetes.core.k8s:
        state: present
        namespace: openstack
        definition:
          apiVersion: v1
          kind: Secret
          type: Opaque
          metadata:
            name: "{{ secret_name }}"
            namespace: openstack
          stringData:
            root-password: "{{ lookup('ansible.builtin.password', '/dev/null', chars=['ascii_letters', 'digits'], length=32) }}"
            password: "{{ lookup('ansible.builtin.password', '/dev/null', chars=['ascii_letters', 'digits'], length=32) }}"
      when: maraiadb_secret_output.resources | length == 0

    - name: Set cluster name in kustomize file
      ansible.builtin.lineinfile:
        path: /opt/genestack/kustomize.example/mariadb-operator/kustomization.yaml
        regexp: "^      clusterName: cluster.local"
        line: "      clusterName: {{ cluster_name }}"

    - name: Deply mariadb operator
      kubernetes.core.k8s:
        definition: "{{ lookup('kubernetes.core.kustomize', binary_path='/usr/local/bin/kubectl', dir='/opt/genestack/kustomize.example/mariadb-operator', enable_helm=True) }}" # yamllint disable-line rule:line-length
        namespace: mariadb-system
        apply: true
        server_side_apply:
          field_manager: ansible
          force_conflicts: true
        state: present

    - name: Wait for mariadb operator webhook pod conditions
      kubernetes.core.k8s_info:
        api_version: v1
        kind: Pod
        label_selectors:
          - app.kubernetes.io/name = mariadb-operator-webhook
        namespace: mariadb-system
        wait: true
        wait_condition:
          type: "{{ item }}"
          status: "True"
      loop:
        - "Ready"
        - "ContainersReady"

    - name: Deploy the mariadb cluster
      kubernetes.core.k8s:
        definition: "{{ lookup('kubernetes.core.kustomize', binary_path='/usr/local/bin/kubectl', dir='/opt/genestack/kustomize.example/mariadb-cluster/base') }}" # yamllint disable-line rule:line-length
        namespace: openstack
        apply: true
        state: present
